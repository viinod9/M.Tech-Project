{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOMTE : Logistic Regression on Credit card fraud detection dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:05:40.352405Z",
     "iopub.status.busy": "2024-10-23T17:05:40.350933Z",
     "iopub.status.idle": "2024-10-23T17:05:43.622061Z",
     "shell.execute_reply": "2024-10-23T17:05:43.620848Z",
     "shell.execute_reply.started": "2024-10-23T17:05:40.352352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the credit card fraud dataset\n",
    "data = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:07:50.535202Z",
     "iopub.status.busy": "2024-10-23T17:07:50.533905Z",
     "iopub.status.idle": "2024-10-23T17:07:50.546650Z",
     "shell.execute_reply": "2024-10-23T17:07:50.545106Z",
     "shell.execute_reply.started": "2024-10-23T17:07:50.535100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original dataset shape:\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"\\nOriginal dataset shape:\")\n",
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:07:59.581702Z",
     "iopub.status.busy": "2024-10-23T17:07:59.581231Z",
     "iopub.status.idle": "2024-10-23T17:07:59.612446Z",
     "shell.execute_reply": "2024-10-23T17:07:59.610997Z",
     "shell.execute_reply.started": "2024-10-23T17:07:59.581656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = data.drop('Class', axis=1)  # Features\n",
    "y = data['Class']               # Target variable (0: non-fraud, 1: fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:08:03.429044Z",
     "iopub.status.busy": "2024-10-23T17:08:03.428011Z",
     "iopub.status.idle": "2024-10-23T17:08:03.620468Z",
     "shell.execute_reply": "2024-10-23T17:08:03.619226Z",
     "shell.execute_reply.started": "2024-10-23T17:08:03.428983Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:08:07.854492Z",
     "iopub.status.busy": "2024-10-23T17:08:07.854014Z",
     "iopub.status.idle": "2024-10-23T17:08:19.891247Z",
     "shell.execute_reply": "2024-10-23T17:08:19.889668Z",
     "shell.execute_reply.started": "2024-10-23T17:08:07.854448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Without SMOTE ---\n",
    "# Train a Logistic Regression model without SMOTE\n",
    "model_without_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_without_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:08:27.150027Z",
     "iopub.status.busy": "2024-10-23T17:08:27.148638Z",
     "iopub.status.idle": "2024-10-23T17:08:27.164761Z",
     "shell.execute_reply": "2024-10-23T17:08:27.162790Z",
     "shell.execute_reply.started": "2024-10-23T17:08:27.149960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_without_smote = model_without_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:08:51.810049Z",
     "iopub.status.busy": "2024-10-23T17:08:51.809565Z",
     "iopub.status.idle": "2024-10-23T17:08:51.829091Z",
     "shell.execute_reply": "2024-10-23T17:08:51.827277Z",
     "shell.execute_reply.started": "2024-10-23T17:08:51.810003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Without SMOTE ---\n",
      "Confusion Matrix:\n",
      "[[56850    14]\n",
      " [   33    65]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"\\n--- Without SMOTE ---\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_without_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:09:01.655218Z",
     "iopub.status.busy": "2024-10-23T17:09:01.654683Z",
     "iopub.status.idle": "2024-10-23T17:09:02.063118Z",
     "shell.execute_reply": "2024-10-23T17:09:02.061452Z",
     "shell.execute_reply.started": "2024-10-23T17:09:01.655169Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- With SMOTE ---\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:09:11.906067Z",
     "iopub.status.busy": "2024-10-23T17:09:11.905625Z",
     "iopub.status.idle": "2024-10-23T17:09:18.959805Z",
     "shell.execute_reply": "2024-10-23T17:09:18.957925Z",
     "shell.execute_reply.started": "2024-10-23T17:09:11.906024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Logistic Regression model on the resampled data\n",
    "model_with_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_with_smote.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:09:45.918029Z",
     "iopub.status.busy": "2024-10-23T17:09:45.917539Z",
     "iopub.status.idle": "2024-10-23T17:09:45.934002Z",
     "shell.execute_reply": "2024-10-23T17:09:45.931676Z",
     "shell.execute_reply.started": "2024-10-23T17:09:45.917965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_with_smote = model_with_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T17:09:48.759591Z",
     "iopub.status.busy": "2024-10-23T17:09:48.758190Z",
     "iopub.status.idle": "2024-10-23T17:09:48.777282Z",
     "shell.execute_reply": "2024-10-23T17:09:48.776076Z",
     "shell.execute_reply.started": "2024-10-23T17:09:48.759539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- With SMOTE ---\n",
      "Confusion Matrix:\n",
      "[[55591  1273]\n",
      " [    9    89]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"\\n--- With SMOTE ---\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_with_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE : Random Forest on credit card fraud detection dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T07:14:48.270559Z",
     "iopub.status.busy": "2024-10-23T07:14:48.270109Z",
     "iopub.status.idle": "2024-10-23T07:29:59.119903Z",
     "shell.execute_reply": "2024-10-23T07:29:59.118511Z",
     "shell.execute_reply.started": "2024-10-23T07:14:48.270511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Original dataset shape:\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Without SMOTE ---\n",
      "Confusion Matrix:\n",
      "[[56859     5]\n",
      " [   18    80]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.94      0.82      0.87        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.91      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Resampled dataset shape:\n",
      "Class\n",
      "0    227451\n",
      "1    227451\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- With SMOTE ---\n",
      "Confusion Matrix:\n",
      "[[56848    16]\n",
      " [   17    81]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.84      0.83      0.83        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.91      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n",
    "\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.drop('Class', axis=1)  # Features\n",
    "y = data['Class']                # Target variable (0: non-fraud, 1: fraud)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# --- Without SMOTE ---\n",
    "# Train a Random Forest model without SMOTE\n",
    "model_without_smote = RandomForestClassifier(random_state=42)\n",
    "model_without_smote.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_without_smote = model_without_smote.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n--- Without SMOTE ---\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_without_smote))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_without_smote))\n",
    "\n",
    "# --- With SMOTE ---\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check resampled class distribution\n",
    "print(\"\\nResampled dataset shape:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# Train a Random Forest model on the resampled data\n",
    "model_with_smote = RandomForestClassifier(random_state=42)\n",
    "model_with_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_with_smote = model_with_smote.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n--- With SMOTE ---\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_with_smote))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_with_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ydata-synthetic : Linear regression on california housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:20:23.361560Z",
     "iopub.status.busy": "2024-10-24T12:20:23.361153Z",
     "iopub.status.idle": "2024-10-24T12:20:40.009552Z",
     "shell.execute_reply": "2024-10-24T12:20:40.008189Z",
     "shell.execute_reply.started": "2024-10-24T12:20:23.361510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ydata-synthetic\n",
      "  Downloading ydata_synthetic-2.0.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting ydata-sdk (from ydata-synthetic)\n",
      "  Downloading ydata_sdk-1.0.1-py310-none-any.whl.metadata (7.4 kB)\n",
      "Collecting httpx==0.23.3 (from ydata-sdk->ydata-synthetic)\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting ydata-core>=0.2.0 (from ydata-sdk->ydata-synthetic)\n",
      "  Downloading ydata_core-0.7.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from ydata-sdk->ydata-synthetic) (2.2.3)\n",
      "Collecting prettytable==3.6.0 (from ydata-sdk->ydata-synthetic)\n",
      "  Downloading prettytable-3.6.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic==1.10.9 (from ydata-sdk->ydata-synthetic)\n",
      "  Downloading pydantic-1.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typeguard==2.13.3 (from ydata-sdk->ydata-synthetic)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting ydata-datascience (from ydata-sdk->ydata-synthetic)\n",
      "  Downloading ydata_datascience-0.7.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.23.3->ydata-sdk->ydata-synthetic) (2024.8.30)\n",
      "Collecting httpcore<0.17.0,>=0.15.0 (from httpx==0.23.3->ydata-sdk->ydata-synthetic)\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.3->ydata-sdk->ydata-synthetic)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.23.3->ydata-sdk->ydata-synthetic) (1.3.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable==3.6.0->ydata-sdk->ydata-synthetic) (0.2.13)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.10.9->ydata-sdk->ydata-synthetic) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->ydata-sdk->ydata-synthetic) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->ydata-sdk->ydata-synthetic) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->ydata-sdk->ydata-synthetic) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->ydata-sdk->ydata-synthetic) (2024.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx==0.23.3->ydata-sdk->ydata-synthetic) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx==0.23.3->ydata-sdk->ydata-synthetic) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->ydata-sdk->ydata-synthetic) (1.16.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.3->ydata-sdk->ydata-synthetic) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx==0.23.3->ydata-sdk->ydata-synthetic) (1.2.0)\n",
      "Downloading ydata_synthetic-2.0.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading ydata_sdk-1.0.1-py310-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prettytable-3.6.0-py3-none-any.whl (27 kB)\n",
      "Downloading pydantic-1.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Downloading ydata_core-0.7.0-py2.py3-none-any.whl (4.6 kB)\n",
      "Downloading ydata_datascience-0.7.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Installing collected packages: ydata-datascience, ydata-core, rfc3986, typeguard, pydantic, prettytable, httpcore, httpx, ydata-sdk, ydata-synthetic\n",
      "  Attempting uninstall: typeguard\n",
      "    Found existing installation: typeguard 4.3.0\n",
      "    Uninstalling typeguard-4.3.0:\n",
      "      Successfully uninstalled typeguard-4.3.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.9.2\n",
      "    Uninstalling pydantic-2.9.2:\n",
      "      Successfully uninstalled pydantic-2.9.2\n",
      "  Attempting uninstall: prettytable\n",
      "    Found existing installation: prettytable 3.10.0\n",
      "    Uninstalling prettytable-3.10.0:\n",
      "      Successfully uninstalled prettytable-3.10.0\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.5\n",
      "    Uninstalling httpcore-1.0.5:\n",
      "      Successfully uninstalled httpcore-1.0.5\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 1.4.17 requires pydantic>=2.7.0, but you have pydantic 1.10.9 which is incompatible.\n",
      "jupyterlab 4.2.5 requires httpx>=0.25.0, but you have httpx 0.23.3 which is incompatible.\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires pydantic>=2, but you have pydantic 1.10.9 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed httpcore-0.16.3 httpx-0.23.3 prettytable-3.6.0 pydantic-1.10.9 rfc3986-1.5.0 typeguard-2.13.3 ydata-core-0.7.0 ydata-datascience-0.7.0 ydata-sdk-1.0.1 ydata-synthetic-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ydata-synthetic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:25:03.029810Z",
     "iopub.status.busy": "2024-10-24T12:25:03.029319Z",
     "iopub.status.idle": "2024-10-24T12:25:14.839649Z",
     "shell.execute_reply": "2024-10-24T12:25:14.838246Z",
     "shell.execute_reply.started": "2024-10-24T12:25:03.029771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ydata-sdk in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: httpx==0.23.3 in /opt/conda/lib/python3.10/site-packages (from ydata-sdk) (0.23.3)\n",
      "Requirement already satisfied: ydata-core>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ydata-sdk) (0.7.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from ydata-sdk) (2.2.3)\n",
      "Requirement already satisfied: prettytable==3.6.0 in /opt/conda/lib/python3.10/site-packages (from ydata-sdk) (3.6.0)\n",
      "Requirement already satisfied: pydantic==1.10.9 in /opt/conda/lib/python3.10/site-packages (from ydata-sdk) (1.10.9)\n",
      "Requirement already satisfied: typeguard==2.13.3 in /opt/conda/lib/python3.10/site-packages (from ydata-sdk) (2.13.3)\n",
      "Requirement already satisfied: ydata-datascience in /opt/conda/lib/python3.10/site-packages (from ydata-sdk) (0.7.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.23.3->ydata-sdk) (2024.8.30)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from httpx==0.23.3->ydata-sdk) (0.16.3)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /opt/conda/lib/python3.10/site-packages (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.3->ydata-sdk) (1.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.23.3->ydata-sdk) (1.3.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable==3.6.0->ydata-sdk) (0.2.13)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.10.9->ydata-sdk) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->ydata-sdk) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->ydata-sdk) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->ydata-sdk) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->ydata-sdk) (2024.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx==0.23.3->ydata-sdk) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx==0.23.3->ydata-sdk) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->ydata-sdk) (1.16.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.3->ydata-sdk) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx==0.23.3->ydata-sdk) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ydata-sdk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:32:16.187360Z",
     "iopub.status.busy": "2024-10-24T12:32:16.186933Z",
     "iopub.status.idle": "2024-10-24T12:32:16.219023Z",
     "shell.execute_reply": "2024-10-24T12:32:16.217269Z",
     "shell.execute_reply.started": "2024-10-24T12:32:16.187323Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'WGAN_GP' from 'ydata.sdk.synthesizers' (/opt/conda/lib/python3.10/site-packages/ydata/sdk/synthesizers/__init__.pyc)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYDATA_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoibWEyM20wMjZAc21haWwuaWl0bS5hYy5pbiIsImVtYWlsIjoibWEyM20wMjZAc21haWwuaWl0bS5hYy5pbiIsImV4cCI6MTczMjM2NDk0OSwiaWF0IjoxNzI5NzcyOTQ5fQ.e2DEF5oOesumXFuZQLbrpO_tRouWbVQyuOSrjatcKJw\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Now you can import the WGAN_GP\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mydata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynthesizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WGAN_GP\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'WGAN_GP' from 'ydata.sdk.synthesizers' (/opt/conda/lib/python3.10/site-packages/ydata/sdk/synthesizers/__init__.pyc)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the YData API token\n",
    "os.environ[\"YDATA_TOKEN\"] = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoibWEyM20wMjZAc21haWwuaWl0bS5hYy5pbiIsImVtYWlsIjoibWEyM20wMjZAc21haWwuaWl0bS5hYy5pbiIsImV4cCI6MTczMjM2NDk0OSwiaWF0IjoxNzI5NzcyOTQ5fQ.e2DEF5oOesumXFuZQLbrpO_tRouWbVQyuOSrjatcKJw\"\n",
    "\n",
    "from ydata.sdk.synthesizers import WGAN_GP\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:21:38.474789Z",
     "iopub.status.busy": "2024-10-24T12:21:38.474298Z",
     "iopub.status.idle": "2024-10-24T12:21:41.170658Z",
     "shell.execute_reply": "2024-10-24T12:21:41.169531Z",
     "shell.execute_reply.started": "2024-10-24T12:21:38.474744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  MedHouseVal  \n",
      "0    -122.23        4.526  \n",
      "1    -122.22        3.585  \n",
      "2    -122.24        3.521  \n",
      "3    -122.25        3.413  \n",
      "4    -122.25        3.422  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop(columns=\"MedHouseVal\")\n",
    "y = df[\"MedHouseVal\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:23:43.448323Z",
     "iopub.status.busy": "2024-10-24T12:23:43.447810Z",
     "iopub.status.idle": "2024-10-24T12:23:43.476999Z",
     "shell.execute_reply": "2024-10-24T12:23:43.474999Z",
     "shell.execute_reply.started": "2024-10-24T12:23:43.448280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Original Data: 0.5558915986952444\n"
     ]
    }
   ],
   "source": [
    "# Train a Linear Regression model on original data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse_original = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error on Original Data: {mse_original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:25:42.630663Z",
     "iopub.status.busy": "2024-10-24T12:25:42.630165Z",
     "iopub.status.idle": "2024-10-24T12:25:43.000949Z",
     "shell.execute_reply": "2024-10-24T12:25:42.999223Z",
     "shell.execute_reply.started": "2024-10-24T12:25:42.630618Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ydata_sdk-1.0.1>/ydata/sdk/common/__init__.py:11: NewUserWarning: \n",
      "YData SDK requires an account with a valid token.\n",
      "\n",
      "In case you do not have an account, please, create one at https://ydata.ai/ydata-fabric-free-trial.\n",
      "To obtain the token, please, login to https://https://fabric.ydata.ai/api.\n",
      "The token is available on the homepage once you are connected.\n",
      "\n",
      "The easiest way to have the client created is to define the token in an environment variable 'YDATA_TOKEN' as follows:\n",
      "\n",
      "\n",
      "    ```\n",
      "    import os\n",
      "    os.environ[\"YDATA_TOKEN\"] = <your_token>\n",
      "    ```\n",
      "\n",
      "See the documentation for further help: https://docs.sdk.ydata.ai/latest/getting-started/installation/\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'WGAN_GP' from 'ydata.sdk.synthesizers' (/opt/conda/lib/python3.10/site-packages/ydata/sdk/synthesizers/__init__.pyc)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mydata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynthesizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WGAN_GP\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'WGAN_GP' from 'ydata.sdk.synthesizers' (/opt/conda/lib/python3.10/site-packages/ydata/sdk/synthesizers/__init__.pyc)"
     ]
    }
   ],
   "source": [
    "from ydata.sdk.synthesizers import WGAN_GP\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Set up the GAN-based synthetic data generator\n",
    "gan = WGAN_GP(batch_size=128, log_step=100, epochs=1000)\n",
    "\n",
    "# Train the GAN model on the training data\n",
    "gan.fit(X_train_scaled, n_cols=X_train.shape[1])\n",
    "\n",
    "# Generate synthetic data\n",
    "synthetic_data = gan.generate(n_samples=X_train.shape[0])\n",
    "\n",
    "# Inverse transform the synthetic data to get it back to the original scale\n",
    "synthetic_data = scaler.inverse_transform(synthetic_data)\n",
    "\n",
    "# Convert synthetic data to DataFrame\n",
    "X_synthetic = pd.DataFrame(synthetic_data, columns=X_train.columns)\n",
    "\n",
    "# For simplicity, we'll assume the target variable is the same (you can synthesize it separately if needed)\n",
    "y_synthetic = y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display first few rows of synthetic data\n",
    "print(X_synthetic.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Linear Regression model on synthetic data\n",
    "model_synthetic = LinearRegression()\n",
    "model_synthetic.fit(X_synthetic, y_synthetic)\n",
    "\n",
    "# Predict on the original test set (to compare with real data)\n",
    "y_pred_synthetic = model_synthetic.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance on real test set\n",
    "mse_synthetic = mean_squared_error(y_test, y_pred_synthetic)\n",
    "print(f\"Mean Squared Error on Synthetic Data: {mse_synthetic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Squared Error on Original Data: {mse_original}\")\n",
    "print(f\"Mean Squared Error on Synthetic Data: {mse_synthetic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN : credit card fraud dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = data.drop('Class', axis=1)  # Features\n",
    "y = data['Class']               # Target variable (0: non-fraud, 1: fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Parameters\n",
    "latent_dim = 32  # Size of the noise vector (latent space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build the Generator\n",
    "generator = Sequential([\n",
    "    Dense(64, input_dim=latent_dim),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(128),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(X_train.shape[1], activation='tanh')  # Output layer size matches features\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build the Discriminator\n",
    "discriminator = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1]),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(64),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(1, activation='sigmoid')  # Output is a probability (real or fake)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Discriminator\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Discriminator during Generator training\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Model (Generator + Discriminator)\n",
    "gan = Sequential([generator, discriminator])\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the GAN\n",
    "epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | D Loss Real: 0.628672182559967 | D Loss Fake: 0.6857059597969055 | G Loss: [array(0.68570596, dtype=float32), array(0.68570596, dtype=float32), array(0.59375, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x177e42340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x177e43a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Sample random noise\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "    # Generate synthetic data\n",
    "    gen_data = generator.predict(noise)\n",
    "\n",
    "    # Select a random subset of real data\n",
    "    real_data_idx = np.random.randint(0, X_train_scaled.shape[0], batch_size)\n",
    "    real_data = X_train_scaled[real_data_idx]\n",
    "\n",
    "    # Create labels for real (1) and fake (0) data\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    # Train Discriminator\n",
    "    d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_data, fake_labels)\n",
    "\n",
    "    # Train the GAN (Generator tries to trick the Discriminator)\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch} | D Loss Real: {d_loss_real[0]} | D Loss Fake: {d_loss_fake[0]} | G Loss: {g_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic samples using the trained Generator\n",
    "num_synthetic_samples = 10000  # Generate more synthetic data\n",
    "noise = np.random.normal(0, 1, (num_synthetic_samples, latent_dim))\n",
    "synthetic_data = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26628289e+05, -1.13946320e+02, -1.66956848e+02, ...,\n",
       "        -7.44089203e+01, -6.39941940e+01,  2.56793828e+04],\n",
       "       [ 4.03849375e+04, -1.12849007e+02, -1.66160019e+02, ...,\n",
       "        -7.57073288e+01, -6.40762024e+01,  2.48052676e+04],\n",
       "       [-5.80579609e+04, -1.09833511e+02, -1.62950546e+02, ...,\n",
       "        -7.14804688e+01, -6.02079811e+01,  2.49221953e+04],\n",
       "       ...,\n",
       "       [ 1.24669195e+05, -1.14510155e+02, -1.67391327e+02, ...,\n",
       "        -7.50804977e+01, -6.41805801e+01,  2.56887090e+04],\n",
       "       [ 8.98164766e+04, -1.13848694e+02, -1.66160355e+02, ...,\n",
       "        -7.43682404e+01, -6.42604599e+01,  2.56704590e+04],\n",
       "       [ 6.36160469e+04, -1.13508682e+02, -1.67249527e+02, ...,\n",
       "        -7.41867294e+01, -6.21154366e+01,  2.51750723e+04]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale back the data\n",
    "synthetic_data = scaler.inverse_transform(synthetic_data)\n",
    "synthetic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTGAN : On credit card fraud dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T07:31:29.262536Z",
     "iopub.status.busy": "2024-10-25T07:31:29.262058Z",
     "iopub.status.idle": "2024-10-25T07:32:34.650246Z",
     "shell.execute_reply": "2024-10-25T07:32:34.648683Z",
     "shell.execute_reply.started": "2024-10-25T07:31:29.262493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting botocore==1.35.16\n",
      "  Downloading botocore-1.35.16-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from botocore==1.35.16) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore==1.35.16) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore==1.35.16) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.35.16) (1.16.0)\n",
      "Downloading botocore-1.35.16-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.35.48\n",
      "    Uninstalling botocore-1.35.48:\n",
      "      Successfully uninstalled botocore-1.35.48\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.35.48 requires botocore<1.36.0,>=1.35.48, but you have botocore 1.35.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.35.16\n",
      "Collecting packaging==23.0\n",
      "  Downloading packaging-23.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: packaging\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.0 which is incompatible.\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "pytoolconfig 1.3.1 requires packaging>=23.2, but you have packaging 23.0 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "xarray 2024.9.0 requires packaging>=23.1, but you have packaging 23.0 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed packaging-23.0\n",
      "Collecting jupyter-lsp==2.0.0\n",
      "  Downloading jupyter_lsp-2.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: jupyter-server>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-lsp==2.0.0) (2.12.5)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (4.4.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (23.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (6.4.5)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (5.10.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (7.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (23.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.20.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (26.0.3)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.18.1)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (5.14.3)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (4.12.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=7.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=7.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=7.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (4.2.2)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (4.22.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (6.0.2)\n",
      "Requirement already satisfied: referencing in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.35.1)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.8.4)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.18.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.3.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (6.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (4.12.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.5.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.1.5)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.19.1)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.10/site-packages (from terminado>=0.8.3->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (21.2.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.18.1)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.4)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (24.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.5)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.1.2->jupyter-lsp==2.0.0) (2.9.0.20240316)\n",
      "Downloading jupyter_lsp-2.0.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jupyter-lsp\n",
      "  Attempting uninstall: jupyter-lsp\n",
      "    Found existing installation: jupyter-lsp 1.5.1\n",
      "    Uninstalling jupyter-lsp-1.5.1:\n",
      "      Successfully uninstalled jupyter-lsp-1.5.1\n",
      "Successfully installed jupyter-lsp-2.0.0\n",
      "Collecting shapely==2.0.1\n",
      "  Downloading shapely-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely==2.0.1) (1.26.4)\n",
      "Downloading shapely-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely\n",
      "  Attempting uninstall: shapely\n",
      "    Found existing installation: Shapely 1.8.5.post1\n",
      "    Uninstalling Shapely-1.8.5.post1:\n",
      "      Successfully uninstalled Shapely-1.8.5.post1\n",
      "Successfully installed shapely-2.0.1\n",
      "/bin/bash: 4: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install botocore==1.35.16\n",
    "!pip install packaging==23.0\n",
    "!pip install jupyter-lsp==2.0.0\n",
    "!pip install shapely==2.0.1\n",
    "!pip install platformdirs<4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Ignored the following yanked versions: 1.13.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 0.10.0 Requires-Python >=3.6,<3.9; 0.10.0.dev0 Requires-Python >=3.6,<3.9; 0.10.1 Requires-Python >=3.6,<3.9; 0.10.1.dev0 Requires-Python >=3.6,<3.9; 0.11.0 Requires-Python >=3.6,<3.9; 0.11.0.dev0 Requires-Python >=3.6,<3.9; 0.12.0 Requires-Python >=3.6,<3.9; 0.12.0.dev0 Requires-Python >=3.6,<3.9; 0.12.0.dev1 Requires-Python >=3.6,<3.9; 0.12.1 Requires-Python >=3.6,<3.9; 0.12.1.dev0 Requires-Python >=3.6,<3.9; 0.13.0 Requires-Python >=3.6,<3.10; 0.13.0.dev0 Requires-Python >=3.6,<3.10; 0.13.1 Requires-Python >=3.6,<3.10; 0.13.1.dev0 Requires-Python >=3.6,<3.10; 0.14.0 Requires-Python >=3.6,<3.10; 0.14.0.dev0 Requires-Python >=3.6,<3.10; 0.14.0.dev1 Requires-Python >=3.6,<3.10; 0.14.0.dev2 Requires-Python >=3.6,<3.10; 0.14.1 Requires-Python >=3.6,<3.10; 0.14.1.dev0 Requires-Python >=3.6,<3.10; 0.15.0 Requires-Python >=3.6,<3.10; 0.15.0.dev0 Requires-Python >=3.6,<3.10; 0.15.0.dev1 Requires-Python >=3.6,<3.10; 0.16.0 Requires-Python >=3.6,<3.10; 0.16.0.dev0 Requires-Python >=3.6,<3.10; 0.16.0.dev1 Requires-Python >=3.6,<3.10; 0.16.0.dev2 Requires-Python >=3.6,<3.10; 0.16.0.dev3 Requires-Python >=3.6,<3.10; 0.16.0.dev4 Requires-Python >=3.6,<3.10; 0.16.0.dev5 Requires-Python >=3.6,<3.10; 0.17.0 Requires-Python >=3.6,<3.10; 0.17.0.dev0 Requires-Python >=3.6,<3.10; 0.17.0.dev1 Requires-Python >=3.6,<3.10; 0.17.0.dev2 Requires-Python >=3.6,<3.10; 0.17.1 Requires-Python >=3.6,<3.10; 0.17.1.dev0 Requires-Python >=3.6,<3.10; 0.17.2 Requires-Python >=3.6,<3.10; 0.17.2.dev0 Requires-Python >=3.6,<3.10; 0.18.0 Requires-Python >=3.7,<3.11; 0.18.0.dev0 Requires-Python >=3.7,<3.11; 0.3.3 Requires-Python >=3.5,<3.8; 0.3.4 Requires-Python >=3.5,<3.8; 0.3.4.dev0 Requires-Python >=3.5,<3.8; 0.3.5 Requires-Python >=3.5,<3.8; 0.3.6 Requires-Python >=3.5,<3.8; 0.3.6.dev0 Requires-Python >=3.5,<3.8; 0.4.0 Requires-Python >=3.5,<3.9; 0.4.0.dev0 Requires-Python >=3.5,<3.9; 0.4.1 Requires-Python >=3.5,<3.9; 0.4.1.dev0 Requires-Python >=3.5,<3.9; 0.4.2 Requires-Python >=3.5,<3.9; 0.4.3 Requires-Python >=3.5,<3.9; 0.4.4 Requires-Python >=3.5,<3.9; 0.4.4.dev0 Requires-Python >=3.5,<3.9; 0.4.5 Requires-Python >=3.6,<3.9; 0.4.6.dev0 Requires-Python >=3.6,<3.9; 0.4.6.dev1 Requires-Python >=3.6,<3.9; 0.4.6.dev2 Requires-Python >=3.6,<3.9; 0.5.0 Requires-Python >=3.6,<3.9; 0.5.0.dev0 Requires-Python >=3.6,<3.9; 0.6.0 Requires-Python >=3.6,<3.9; 0.6.0.dev0 Requires-Python >=3.6,<3.9; 0.6.1 Requires-Python >=3.6,<3.9; 0.6.2.dev0 Requires-Python >=3.6,<3.9; 0.6.2.dev1 Requires-Python >=3.6,<3.9; 0.6.2.dev2 Requires-Python >=3.6,<3.9; 0.7.0 Requires-Python >=3.6,<3.9; 0.7.0.dev0 Requires-Python >=3.6,<3.9; 0.7.0.dev1 Requires-Python >=3.6,<3.9; 0.8.0 Requires-Python >=3.6,<3.9; 0.8.0.dev0 Requires-Python >=3.6,<3.9; 0.9.0 Requires-Python >=3.6,<3.9; 0.9.0.dev0 Requires-Python >=3.6,<3.9; 0.9.1 Requires-Python >=3.6,<3.9; 0.9.1.dev0 Requires-Python >=3.6,<3.9; 0.9.1.dev1 Requires-Python >=3.6,<3.9; 1.0.0 Requires-Python >=3.7,<3.11; 1.0.0b0 Requires-Python >=3.7,<3.11; 1.0.0b1 Requires-Python >=3.7,<3.11; 1.0.0rc0 Requires-Python >=3.7,<3.11; 1.0.1 Requires-Python >=3.7,<3.11; 1.0.1.dev0 Requires-Python >=3.7,<3.11; 1.1.0 Requires-Python >=3.7,<3.11; 1.1.0.dev0 Requires-Python >=3.7,<3.11; 1.10.0 Requires-Python >=3.8,<3.12; 1.10.0.dev0 Requires-Python >=3.8,<3.12; 1.11.0 Requires-Python <3.12,>=3.8; 1.11.0.dev0 Requires-Python <3.12,>=3.8; 1.2.0 Requires-Python >=3.7,<3.11; 1.2.0.dev0 Requires-Python >=3.7,<3.11; 1.2.0.dev1 Requires-Python >=3.7,<3.11; 1.2.1 Requires-Python >=3.8,<3.11; 1.2.1.dev0 Requires-Python >=3.8,<3.11; 1.2.2.dev0 Requires-Python >=3.8,<3.11; 1.2.2.dev1 Requires-Python >=3.8,<3.11; 1.3.0 Requires-Python >=3.8,<3.12; 1.3.0.dev0 Requires-Python >=3.8,<3.12; 1.3.0.dev1 Requires-Python >=3.8,<3.12; 1.4.0 Requires-Python >=3.8,<3.12; 1.4.0.dev0 Requires-Python >=3.8,<3.12; 1.4.0.dev1 Requires-Python >=3.8,<3.12; 1.5.0 Requires-Python >=3.8,<3.12; 1.5.0.dev0 Requires-Python >=3.8,<3.12; 1.6.0 Requires-Python >=3.8,<3.12; 1.6.0.dev0 Requires-Python >=3.8,<3.12; 1.6.0.dev1 Requires-Python >=3.8,<3.12; 1.7.0 Requires-Python >=3.8,<3.12; 1.7.0.dev0 Requires-Python >=3.8,<3.12; 1.8.0 Requires-Python >=3.8,<3.12; 1.8.0.dev0 Requires-Python >=3.8,<3.12; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0.dev0 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement sdv==0.18.0 (from versions: 0.0.0, 0.1.0, 0.1.1, 0.1.2, 0.2.0.dev0, 0.2.0, 0.2.1, 0.2.2, 0.3.0, 0.3.1, 0.3.2, 1.12.0.dev0, 1.12.0, 1.12.1.dev0, 1.12.1.dev1, 1.12.1, 1.13.0.dev0, 1.13.1.dev0, 1.13.1, 1.14.0.dev0, 1.14.0, 1.15.0.dev0, 1.15.0, 1.16.0.dev0, 1.16.0, 1.16.1.dev0, 1.16.1, 1.16.2.dev0, 1.16.2, 1.17.0.dev0, 1.17.0.dev1, 1.17.0, 1.17.1.dev0, 1.17.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for sdv==0.18.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install sdv==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sdv.tabular'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGAN\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreditcard.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sdv.tabular'"
     ]
    }
   ],
   "source": [
    "from sdv.tabular import CTGAN\n",
    "\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "X = data.drop('Class', axis=1)  \n",
    "y = data['Class']              \n",
    "\n",
    "data_full = pd.concat([X, y], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Prepare data for CTGAN (CTGAN needs the full dataset with features and target in one DataFrame)\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T07:33:53.514822Z",
     "iopub.status.busy": "2024-10-25T07:33:53.514384Z",
     "iopub.status.idle": "2024-10-25T07:33:53.573665Z",
     "shell.execute_reply": "2024-10-25T07:33:53.572107Z",
     "shell.execute_reply.started": "2024-10-25T07:33:53.514781Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CTGAN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize and train CTGAN model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ctgan \u001b[38;5;241m=\u001b[39m \u001b[43mCTGAN\u001b[49m(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m ctgan\u001b[38;5;241m.\u001b[39mfit(train_data)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Generate synthetic fraud samples (Class = 1)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CTGAN' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize and train CTGAN model\n",
    "ctgan = CTGAN(epochs=100)\n",
    "ctgan.fit(train_data)\n",
    "\n",
    "# Generate synthetic fraud samples (Class = 1)\n",
    "conditions = {'Class': 1}\n",
    "synthetic_data = ctgan.sample(10000, conditions=conditions)\n",
    "\n",
    "# Separate fraud and non-fraud samples in the original training data\n",
    "fraud_samples = X_train[y_train == 1]\n",
    "non_fraud_samples = X_train[y_train == 0]\n",
    "\n",
    "# Combine original non-fraud samples with synthetic fraud samples\n",
    "X_augmented = pd.concat([non_fraud_samples, synthetic_data.drop('Class', axis=1)])  # Drop Class from synthetic data\n",
    "y_augmented = pd.concat([y_train[y_train == 0], pd.Series([1] * len(synthetic_data))])  # Labels: 1 for synthetic data\n",
    "\n",
    "# Train Random Forest model with augmented data\n",
    "model_ctgan = RandomForestClassifier(random_state=42)\n",
    "model_ctgan.fit(X_augmented, y_augmented)\n",
    "\n",
    "# Evaluate the model on the original test set\n",
    "y_pred_ctgan = model_ctgan.predict(X_test)\n",
    "\n",
    "print(\"\\n--- CTGAN Augmented Data ---\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ctgan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3650114,
     "sourceId": 6339987,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
